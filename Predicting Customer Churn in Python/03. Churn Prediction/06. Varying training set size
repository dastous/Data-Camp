#The size of your training and testing sets influences model performance. Models learn better when they have more training data. However, there's a risk that they overfit to the training data and don't generalize well to new data, so in order to properly evaluate the model's ability to generalize, you need enough testing data. As a result, there is a important balance and trade-off involved between how much you use for training and how much you hold for testing.
#So far, you've used 70% for training and 30% for testing. Let's now use 80% of the data for training and evaluate how that changes the model's performance.

#Instructions 1/3
#35 XP
#Create training and testing sets, with 80% of data used for training and 20% held for testing.

# Import train_test_split
from sklearn.model_selection import train_test_split

# Create feature variable
X = telco.drop('Churn', axis=1)

# Create target variable
y = telco['Churn']

# Create training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)

#Instructions 2/3
#35 XP
#A RandomForestClassifier has been fit to the new training set. Print its confusion matrix.

# Import train_test_split
from sklearn.model_selection import train_test_split

# Create feature variable
X = telco.drop('Churn', axis=1)

# Create target variable
y = telco['Churn']

# Create training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Import RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier

# Instantiate the classifier
clf = RandomForestClassifier()

# Fit to the training data
clf.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = clf.predict(X_test)

# Import confusion_matrix
from sklearn.metrics import confusion_matrix

# Print confusion matrix
print(confusion_matrix(y_test,y_pred))

#Instructions 3/3
#30 XP
#Question
#As a reminder, here's the output from the previous confusion matrix:
#Previous confusion matrix
#Analyze the new confusion matrix and select the correct statement from the options below.

#Possible Answers
#This classifier made 628 correct predictions, while the previous classifier made 934 correct predictions. As a result, the previous classifier was better.
#This classifier has a higher recall than the previous classifier.
#This classifier has a higher precision than the previous classifier.
#This classifier has a lower accuracy than the previous classifier.**

