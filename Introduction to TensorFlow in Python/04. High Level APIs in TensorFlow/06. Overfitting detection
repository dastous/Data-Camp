#Overfitting detection
#In this exercise, we'll work with a small subset of the examples from the original sign language letters dataset. A small sample, coupled with a heavily-parameterized model, will generally lead to overfitting. This means that your model will simply memorize the class of each example, rather than identifying features that generalize to many examples.

#You will detect overfitting by checking the validation sample to see whether it tends to perform worse than the training sample. With a small sample and a high learning rate, the model will struggle to converge on an optimum. You will set a low learning rate for the optimizer, which will make it easier to identify overfitting.

#Note that keras has been imported from tensorflow.

#Instructions
#100 XP
#Define a sequential model in keras named model.
#Add a first dense layer with 512 nodes, an input shape of (784,), and a relu activation.
#Set the learning rate to 0.0001.
#Set the fit() operation to iterate over the full sample 50 times and use 50% of the sample for validation purposes.

# Define sequential model
model = keras.Sequential()

# Define the first layer
model.add(keras.layers.Dense(512, activation='relu', input_shape=(784,)))

# Add activation function to classifier
model.add(keras.layers.Dense(4, activation='softmax'))

# Finish the model compilation
model.compile(optimizer=keras.optimizers.Adam(lr=0.0001), 
              loss='categorical_crossentropy', metrics=['accuracy'])

# Complete the model fit operation
model.fit(sign_language_features, sign_language_labels, epochs=50, validation_split=0.5)
